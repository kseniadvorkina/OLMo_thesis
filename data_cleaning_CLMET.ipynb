{
 "cells": [
  {
   "cell_type": "code",
   "id": "fedb96bb-3325-4d35-b4e1-9801b0cf3125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:18.858134Z",
     "start_time": "2025-07-22T18:45:18.604993Z"
    }
   },
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "07126ad6-f8a2-40e3-88dd-109f50b7071b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:18.870519Z",
     "start_time": "2025-07-22T18:45:18.866393Z"
    }
   },
   "source": [
    "# Function to extract metadata and text from a file\n",
    "def extract_metadata(file_path):\n",
    "    metadata = {}\n",
    "    text_lines = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        in_metadata_section = True\n",
    "        for line in file:\n",
    "            # Extract metadata lines starting with #\n",
    "            if in_metadata_section:\n",
    "                if line.startswith('#'):\n",
    "                    # Split the line by ': ' and ensure we have two parts (key-value pair)\n",
    "                    parts = line[2:].strip().split(': ', 1)\n",
    "                    if len(parts) == 2:\n",
    "                        key, value = parts\n",
    "                        metadata[key] = value\n",
    "                else:\n",
    "                    in_metadata_section = False\n",
    "                    # First non-metadata line, start collecting text content\n",
    "                    text_lines.append(line.strip())\n",
    "            else:\n",
    "                # Collect text content after metadata\n",
    "                text_lines.append(line.strip())\n",
    "\n",
    "    # Join text lines to form the full text content\n",
    "    text_content = \"\\n\".join(text_lines)\n",
    "\n",
    "    return metadata, text_content\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "a0324a29-a651-486d-8ccf-a4711f81c3d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:20.988450Z",
     "start_time": "2025-07-22T18:45:20.377642Z"
    }
   },
   "source": [
    "# Please make sure to download CLMET dataset and place all texts in .txt (default) in the folder specified under txt_folder\n",
    "# Folder containing the text files\n",
    "txt_folder = \"/Users/kseniadvorkina/Documents/clmet cleaned/txt\"\n",
    "\n",
    "# Initialize lists to store metadata and text content\n",
    "metadata_list = []\n",
    "text_list = []\n",
    "\n",
    "# Iterate over all text files in the directory\n",
    "for filename in os.listdir(txt_folder):\n",
    "    if filename.endswith('.txt'):\n",
    "        file_path = os.path.join(txt_folder, filename)\n",
    "        metadata, text_content = extract_metadata(file_path)\n",
    "        metadata_list.append(metadata)\n",
    "        text_list.append(text_content)\n",
    "\n",
    "# Convert the metadata list into a pandas DataFrame\n",
    "df_metadata = pd.DataFrame(metadata_list)\n",
    "\n",
    "# Add the text content as a new column in the DataFrame\n",
    "df_metadata['text'] = text_list"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "bc90f344-29c4-4287-af9c-098f98bd5482",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:28.937366Z",
     "start_time": "2025-07-22T18:45:28.930507Z"
    }
   },
   "source": [
    "def clean_text(text):\n",
    "    # Step 1: Print and remove all patterns matching \"} number {\" and \"} numberX {\"\n",
    "    #matches_curly_braces = re.findall(r'\\} ?(\\d{1,3}[a-cA-C]?) ?\\{', text)\n",
    "    #for match in matches_curly_braces:\n",
    "    #    print(f\"Found in curly braces: }} {match} {{\")\n",
    "    text = re.sub(r'\\} ?\\d{1,3}[a-cA-C]? ?\\{', '', text)\n",
    "\n",
    "    # Step 2: Print and remove all patterns matching \"[ number ]\"\n",
    "    #matches_square_brackets = re.findall(r'\\[ ?(\\d{1,3}) ?\\]', text)\n",
    "    #for match in matches_square_brackets:\n",
    "    #    print(f\"Found in square brackets: [ {match} ]\")\n",
    "    text = re.sub(r'\\[ ?\\d{1,3} ?\\]', '', text)\n",
    "    # step 2.1: same as 2 but extra spaces [ 1 ]\n",
    "    text = re.sub(r'\\[\\s*\\d+\\s*\\]', '', text)\n",
    "\n",
    "    \n",
    "\n",
    "    # Step 2.2: Print and remove patterns like \"[  pg 154  ]\" and \"[  Pg 154  ]\"\n",
    "    #matches_pg_brackets = re.findall(r'\\[ ?[pP][gG] ?(\\d{1,3}) ?\\]', text)\n",
    "    #for match in matches_pg_brackets:\n",
    "    #    print(f\"Found page reference: [ pg {match} ]\")\n",
    "    text = re.sub(r'\\[ ?[pP][gG] ?\\d{1,3} ?\\]', '', text)\n",
    "    # step 2.3: same as 2.1 but extra spaces [ pg 154 ] or [ Pg 10 ] \n",
    "    text = re.sub(r'\\[\\s*[pP][gG]\\s*\\d+\\s*\\]', '', text)\n",
    "\n",
    "    # step 2.4: same but p\n",
    "    text = re.sub(r'\\[\\s*[pP]\\s*\\d+\\s*\\]', '', text)\n",
    "\n",
    "    # Step 3: Remove all patterns matching \"ßnumber.\" or \"ß number\"\n",
    "    text = re.sub(r'ß ?\\d{1,3}\\.', '', text)\n",
    "    text = re.sub(r'ß ?\\d{1,3}', '', text)\n",
    "\n",
    "    # Step 4: Remove \"* * * * *\"\n",
    "    text = re.sub(r'\\* \\* \\* \\* \\*', '', text)\n",
    "\n",
    "    # Step 5: Remove words ending with \"IToC\" (e.g., \"IIIToC\", \"SomeWordIToC\")\n",
    "    text = re.sub(r'\\b\\w*IToC\\b', '', text)\n",
    "\n",
    "    # Step 6: Remove tags like <page type=\"Page 50\"/>\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "\n",
    "    # Step 7: Replace multiple newlines with a single one\n",
    "    text = re.sub(r'\\n+', '\\n', text).strip()\n",
    "\n",
    "    # Step 8: Handle specific square bracket cases (Illustration, Footnotes)\n",
    "    #matches_specific_brackets = re.findall(r'\\[ ?([^\\]]*Illustration[^\\]]*|[^\\]]*Footnote[^\\]]*) ?\\]', text)\n",
    "    #for match in matches_specific_brackets:\n",
    "    #    print(f\"Found specific content in square brackets: [ {match} ]\")\n",
    "    #text = re.sub(r'\\[ ?([^\\]]*Illustration[^\\]]*|[^\\]]*Footnote[^\\]]*) ?\\]', '', text)\n",
    "\n",
    "    # Step 8.1: Handle Illustrations\n",
    "    #matches_specific_brackets = re.findall(r'\\[ ?(Illustration[^\\]]*|illustration[^\\]]*) ?\\]', text)\n",
    "    #for match in matches_specific_brackets:\n",
    "    #    print(f\"Found specific content in square brackets: [ {match} ]\")\n",
    "    #text = re.sub(r'\\[ ?(Illustration[^\\]]*|illustration[^\\]]*) ?\\]', '', text)\n",
    "    # only cleaning out illustrations withous context\n",
    "    text = re.sub(r'\\[\\s*illustration\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "    # same for image\n",
    "    text = re.sub(r'\\[\\s*image\\s*\\]', '', text, flags=re.IGNORECASE)\n",
    "\n",
    "\n",
    "    # Step 8.1: Handle footnotes\n",
    "    #matches_specific_brackets = re.findall(r'\\[ ?([^\\]]*Footnote[^\\]]*) ?\\]', text)\n",
    "    #for match in matches_specific_brackets:\n",
    "    #    print(f\"Found specific content in square brackets: [ {match} ]\")\n",
    "    #text = re.sub(r'\\[ ?([^\\]]*Footnote[^\\]]*) ?\\]', '', text)\n",
    "\n",
    "    # for [ 11a ] [ 11b ] [ 103a ]\n",
    "    text = re.sub(r'\\[\\s*\\d+[a-zA-Z]\\s*\\]', '', text)\n",
    "\n",
    "    # for [ A ] [ B ]\n",
    "    text = re.sub(r'\\[\\s*[A-Za-z]\\s*\\]', '', text)\n",
    "\n",
    "    # for [ Greek: kekalummenon ] [ Greek: tê Zachariou marturia ]\n",
    "    #text = re.sub(r'\\[\\s*Greek:\\s*[^\\]]+\\s*\\]', '', text)\n",
    "\n",
    "    # change three or more ? to two\n",
    "    text = re.sub(r'\\?{3,}', '??', text)\n",
    "\n",
    "    # strip of µ and ß\n",
    "    #text = re.sub(r'[µß]', '', text)\n",
    "\n",
    "    # weird greek stuff [ ) e  ] [  = i  ] [  = o  ] [  = i  ] [ ) e  ]\n",
    "    text = re.sub(r'\\[\\s*[=\\)]\\s*[a-zA-Z]\\s*\\]', '', text)\n",
    "\n",
    "    # standartise the brackets for missing words to [... ]\n",
    "    text = re.sub(r'\\[\\s*[\\*\\.\\s]+\\s*\\]', '[... ]', text)\n",
    "\n",
    "\n",
    "    '''\n",
    "    # print out everything else remaining in brackets but the footnotes\n",
    "    matches = re.findall(r'\\[([^\\]]*)\\]', text)  # Match anything inside square brackets\n",
    "    for match in matches:\n",
    "        if not (re.search(r'\\b(Footnote|Transcriber|Note|Endnote|Footenote)\\b', match, re.IGNORECASE) or\n",
    "                re.match(r'\\s*\\d{1,3}:\\d\\s*', match) or                           # [  13:1  ] [  123:1  ] [  1:1  ]\n",
    "                re.match(r'\\s*\\.\\.\\.\\s*', match) or                               # [... ] [ ...  ]\n",
    "                re.match(r'\\s*\\*+\\s*', match)                                     # [  **  ] [  *  ]\n",
    "        ):\n",
    "            print(f\"Removing: [ {match} ]\")\n",
    "            # Remove the entire bracket including content\n",
    "            #text = re.sub(re.escape(f'[{match}]'), '', text, count=1)\n",
    "    '''\n",
    "    \n",
    "    # Remove any leftover empty pairs of brackets\n",
    "    text = re.sub(r'\\[\\s*\\]', '', text)\n",
    "\n",
    "    \n",
    "    return text"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "183ecc3b-0080-4dbd-abba-bc7101badaaf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:32.545148Z",
     "start_time": "2025-07-22T18:45:32.539628Z"
    }
   },
   "source": [
    "# test of the data cleaning function\n",
    "sample_text = \"\"\"\n",
    "ß1. ß 5. ß105\n",
    "[ 9 ] [ 10 ]\n",
    "} 2 { } 99 { } 8a { } 8b { } 8c {\n",
    "<page type=\"Page 50\"/>\n",
    "* * * * *\n",
    "IIIToC VIToC IToC\n",
    "\n",
    "Multiple\\n\\n\\nnewlines.\n",
    "\n",
    "[ Footnote 2: Mrs. Byron died August I, 1811. ]\n",
    "\n",
    "[ Footnote 3: For R. C. Dallas, see ` Letters ', vol.\n",
    "i. p. 168, note 1.\n",
    "[ Footnote 1 to Letter 87 ] ]\n",
    "\n",
    "[ bhabka ]\n",
    "\n",
    "[ Illustration ]\n",
    "\n",
    "[ Illustration: MRS SIDDONS and MR KEMBLE as Mr. & Mrs. Beverley Act 5.\n",
    "Sc.\n",
    "4.\n",
    "Bev.\n",
    "O!\n",
    "for a few short Moments to tell you how my Heart bleeds for you. ]\n",
    "\n",
    "[  pg 154  ] [  Pg 10  ] [  1  ]\n",
    "\n",
    "[ Pg 50 ] [ pg 35 ] [ 1 ] [ 999 ]\n",
    "\n",
    "[  Transcriber 's note: ` curosity ' in original  ]\n",
    "[ * Note: See Appendix II. ]\n",
    "\n",
    "[  13:1  ] [  123:1  ] [  1:1  ]\n",
    "\n",
    "[  ENDNOTES  ] [  Endnote 1:1  ]\n",
    "\n",
    "[... ] [ ...  ]\n",
    "\n",
    "[  **  ] [  *  ]\n",
    "\n",
    "to add: [  11a  ] [  11b  ] [  103a  ] [  A  ] [  B  ] [  Greek: kekalummenon  ] [  Greek: tê Zachariou marturia  ]\n",
    "µ ß?\n",
    "\n",
    "?????? (more than two ? i a row)\n",
    "\n",
    "[ ) e  ] [  = i  ] [  = o  ] [  = i  ] [ ) e  ]\n",
    "[] [\n",
    "\n",
    "Done\n",
    "\"\"\"\n",
    "\n",
    "cleaned = clean_text(sample_text)\n",
    "print(\"\\nCleaned Text:\")\n",
    "print(cleaned)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaned Text:\n",
      "Multiple\n",
      "newlines.\n",
      "[ Footnote 2: Mrs. Byron died August I, 1811. ]\n",
      "[ Footnote 3: For R. C. Dallas, see ` Letters ', vol.\n",
      "i. p. 168, note 1.\n",
      "[ Footnote 1 to Letter 87 ] ]\n",
      "[ bhabka ]\n",
      "\n",
      "[ Illustration: MRS SIDDONS and MR KEMBLE as Mr. & Mrs. Beverley Act 5.\n",
      "Sc.\n",
      "4.\n",
      "Bev.\n",
      "O!\n",
      "for a few short Moments to tell you how my Heart bleeds for you. ]\n",
      "  \n",
      "   \n",
      "[  Transcriber 's note: ` curosity ' in original  ]\n",
      "[ * Note: See Appendix II. ]\n",
      "[  13:1  ] [  123:1  ] [  1:1  ]\n",
      "[  ENDNOTES  ] [  Endnote 1:1  ]\n",
      "[... ] [... ]\n",
      "[... ] [... ]\n",
      "to add:      [  Greek: kekalummenon  ] [  Greek: tê Zachariou marturia  ]\n",
      "µ ß?\n",
      "?? (more than two ? i a row)\n",
      "    \n",
      " [\n",
      "Done\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "ecfbb6ab-b22c-4a50-97de-dfe2bacc47bd",
   "metadata": {
    "scrolled": true,
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:51.825762Z",
     "start_time": "2025-07-22T18:45:44.775009Z"
    }
   },
   "source": [
    "df_metadata['cleaned_text'] = df_metadata.apply(\n",
    "    lambda row: print(f\"Processing ID: {row['ID']}\") or clean_text(row['text']), axis=1\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_277\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_263\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_288\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_20\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_34\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_303\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_110\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_317\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_104\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_138\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_139\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_105\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_316\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_111\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_302\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_35\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_21\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_289\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_262\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_276\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_260\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_274\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_248\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_37\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_23\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_314\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_107\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_300\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_113\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_328\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_99\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_98\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_329\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_112\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_301\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_106\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_315\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_22\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_36\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_249\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_275\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_261\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_259\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_265\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_271\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_32\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_26\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_102\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_311\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_116\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_305\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_89\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_304\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_117\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_310\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_103\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_27\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_33\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_270\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_264\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_258\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_272\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_266\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_8\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_299\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_25\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_31\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_19\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_129\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_115\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_306\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_101\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_312\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_313\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_100\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_307\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_114\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_128\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_18\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_30\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_24\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_298\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_267\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_9\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_273\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_214\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_200\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_228\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_43\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_57\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_80\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_189\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_173\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_167\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_166\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_172\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_188\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_81\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_56\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_42\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_229\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_201\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_215\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_203\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_217\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_68\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_54\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_40\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_83\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_164\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_170\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_158\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_159\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_171\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_165\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_82\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_41\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_55\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_69\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_216\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_202\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_206\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_212\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_51\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_45\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_79\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_86\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_149\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_161\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_175\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_174\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_160\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_148\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_87\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_78\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_50\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_213\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_207\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_239\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_211\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_205\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_46\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_52\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_198\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_85\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_176\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_162\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_163\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_177\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_84\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_199\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_53\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_47\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_204\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_210\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_238\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_235\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_221\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_209\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_62\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_76\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_194\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_152\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_146\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_185\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_184\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_147\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_153\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_195\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_88\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_77\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_63\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_208\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_220\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_234\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_222\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_236\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_49\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_75\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_61\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_197\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_145\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_151\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_179\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_186\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_187\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_178\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_150\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_144\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_196\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_74\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_48\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_237\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_223\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_227\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_233\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_70\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_64\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_58\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_192\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_168\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_140\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_154\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_183\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_182\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_155\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_141\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_169\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_193\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_59\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_65\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_71\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_232\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_226\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_218\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_230\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_224\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_67\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_73\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_191\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_157\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_143\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_180\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_181\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_142\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_156\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_190\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_72\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_66\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_225\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_231\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_219\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_256\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_242\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_4\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_295\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_281\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_29\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_15\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_322\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_131\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_125\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_119\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_93\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_92\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_118\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_124\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_130\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_323\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_14\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_28\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_280\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_294\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_5\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_243\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_257\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_241\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_255\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_7\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_269\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_282\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_296\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_16\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_126\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_321\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_132\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_309\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_90\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_91\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_308\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_133\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_320\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_127\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_17\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_297\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_283\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_6\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_268\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_254\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_240\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_278\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_2\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_244\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_250\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_287\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_293\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_13\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_318\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_123\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_330\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_137\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_324\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_95\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_94\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_325\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_136\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_331\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_122\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_319\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_12\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_292\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_286\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_251\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_245\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_3\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_279\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_1\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_253\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_247\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_290\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_284\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_10\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_38\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_108\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_134\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_327\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_120\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_333\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_96\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_97\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_332\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_121\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_326\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_135\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_2_109\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_39\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_1_11\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_285\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_291\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_246\n",
      "Processing ID: histcorp-english-clmet-CLMET3_1_3_252\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "ce9ddce2-365f-4deb-aa25-bcfa5515f223",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:54.270522Z",
     "start_time": "2025-07-22T18:45:54.266272Z"
    }
   },
   "source": "df = df_metadata.copy()",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "raw",
   "id": "807cd6d1-09f6-4927-b752-5a6f1d3b551d",
   "metadata": {},
   "source": "#df.to_csv(\"clmet_cleaned.csv\", index = False)"
  },
  {
   "cell_type": "markdown",
   "id": "ccb12e92-3294-4128-8a14-8d1b60d95b2e",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "cell_type": "code",
   "id": "cbe5c19b-77cf-417e-a301-df9b69584dba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:45:58.234954Z",
     "start_time": "2025-07-22T18:45:58.220632Z"
    }
   },
   "source": [
    "def assign_year_range(year):\n",
    "    if 1710 <= year < 1780:\n",
    "        return \"[1710-1780]\"\n",
    "    elif 1780 <= year < 1850:\n",
    "        return \"[1780-1850]\"\n",
    "    elif 1850 <= year <= 1920:  # Adjust for any future range\n",
    "        return \"[1850-1920]\"\n",
    "    else:\n",
    "        return \"Unknown\"  # If the year does not fit in the defined ranges\n",
    "\n",
    "\n",
    "df.loc[:, 'printedDate'] = pd.to_numeric(df['printedDate'], errors='coerce')\n",
    "df.loc[:, 'yearRange'] = df['printedDate'].apply(assign_year_range)\n",
    "df = df[df['yearRange'] != 'Unknown']  # Make sure this is done on the DataFrame itself\n",
    "df.loc[:, 'words'] = pd.to_numeric(df['words'].replace({',': ''}, regex=True), errors='coerce')\n",
    "word_counts_by_range = df.groupby('yearRange')['words'].sum().to_dict()\n",
    "df.loc[:, 'totalWordsInRange'] = df['yearRange'].map(word_counts_by_range)\n",
    "df.loc[:, 'weight'] = df['words'] / df['totalWordsInRange']"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "8e3d421f-3077-4aa0-b314-cd0b7e4b77d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:46:00.196383Z",
     "start_time": "2025-07-22T18:46:00.191555Z"
    }
   },
   "source": [
    "def split_by_weight(df, train_ratio=0.8, val_ratio=0.1, test_ratio=0.1, random_seed=50):\n",
    "    \"\"\"\n",
    "    Splits the dataframe into train, validation, and test sets based on weights.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe containing the texts to split.\n",
    "        train_ratio (float): Proportion of data for training.\n",
    "        val_ratio (float): Proportion of data for validation.\n",
    "        test_ratio (float): Proportion of data for testing.\n",
    "        random_seed (int): Seed for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Three dataframes - train, validation, and test.\n",
    "    \"\"\"\n",
    "    # Shuffle the dataframe\n",
    "    df = df.sample(frac=1, random_state=random_seed).reset_index(drop=True)\n",
    "\n",
    "    # Calculate cumulative weights\n",
    "    df['cumulative_weight'] = df['weight'].cumsum()\n",
    "    total_weight = df['weight'].sum()\n",
    "\n",
    "    # Define weight thresholds\n",
    "    train_threshold = total_weight * train_ratio\n",
    "    val_threshold = total_weight * (train_ratio + val_ratio)\n",
    "\n",
    "    # Split based on thresholds\n",
    "    train_df = df[df['cumulative_weight'] <= train_threshold]\n",
    "    val_df = df[(df['cumulative_weight'] > train_threshold) & (df['cumulative_weight'] <= val_threshold)]\n",
    "    test_df = df[df['cumulative_weight'] > val_threshold]\n",
    "\n",
    "    # Drop cumulative weight column before returning\n",
    "    train_df = train_df.drop(columns=['cumulative_weight'])\n",
    "    val_df = val_df.drop(columns=['cumulative_weight'])\n",
    "    test_df = test_df.drop(columns=['cumulative_weight'])\n",
    "\n",
    "    return train_df, val_df, test_df"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "7dc90f19-d143-45a9-a764-0e63e7f890b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T18:46:04.129007Z",
     "start_time": "2025-07-22T18:46:04.108940Z"
    }
   },
   "source": [
    "train_dfs = []\n",
    "val_dfs = []\n",
    "test_dfs = []\n",
    "\n",
    "for year_range in df['yearRange'].unique():\n",
    "    subset = df[df['yearRange'] == year_range]\n",
    "    train_split, val_split, test_split = split_by_weight(subset)\n",
    "    train_dfs.append(train_split)\n",
    "    val_dfs.append(val_split)\n",
    "    test_dfs.append(test_split)\n",
    "\n",
    "# Combine splits from all year ranges\n",
    "train_df = pd.concat(train_dfs).reset_index(drop=True)\n",
    "val_df = pd.concat(val_dfs).reset_index(drop=True)\n",
    "test_df = pd.concat(test_dfs).reset_index(drop=True)\n",
    "\n",
    "\n",
    "# check the split\n",
    "def word_count_matrix(df_train, df_val, df_test):\n",
    "    # Group by 'yearRange' and sum 'words' in each split\n",
    "    train_words = df_train.groupby('yearRange')['words'].sum()\n",
    "    val_words = df_val.groupby('yearRange')['words'].sum()\n",
    "    test_words = df_test.groupby('yearRange')['words'].sum()\n",
    "\n",
    "    total_words = train_words + val_words + test_words\n",
    "\n",
    "    # Create a matrix (DataFrame) for easier visualization\n",
    "    matrix = pd.DataFrame({\n",
    "        'Train': train_words,\n",
    "        'Validation': val_words,\n",
    "        'Test': test_words,\n",
    "        'Train %': round(100*train_words/total_words, 3),\n",
    "        'Validation %': round(100*val_words/total_words, 3),\n",
    "        'Test %': round(100*test_words/total_words, 3),\n",
    "    }).fillna(0)  # Fill NaN with 0 for year ranges that may not appear in a particular split\n",
    "\n",
    "    return matrix\n",
    "\n",
    "# Get the word count matrix\n",
    "word_count_matrix_df = word_count_matrix(train_df, val_df, test_df)\n",
    "\n",
    "print(word_count_matrix_df)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Train  Validation     Test    Train %  Validation %     Test %\n",
      "yearRange                                                                     \n",
      "[1710-1780]   6866089      809985   946891  79.625616      9.393347  10.981037\n",
      "[1780-1850]   8664774      899176  1315599  79.642768      8.264828  12.092404\n",
      "[1850-1920]  11162763     1398787  1407057  79.913215     10.013790  10.072994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/q6/1xg_n3r146l5svwv9j_l1t9w0000gn/T/ipykernel_40943/1296993739.py:28: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  matrix = pd.DataFrame({\n"
     ]
    }
   ],
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
