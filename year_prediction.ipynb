{
 "cells": [
  {
   "cell_type": "code",
   "id": "fedb96bb-3325-4d35-b4e1-9801b0cf3125",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:20:55.565981Z",
     "start_time": "2025-07-22T21:20:55.274341Z"
    }
   },
   "source": "import pandas as pd",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:20:56.579738Z",
     "start_time": "2025-07-22T21:20:56.569510Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Here, please use the output csv file produced during soft gating of MoE\n",
    "df = pd.read_csv(\"/Users/kseniadvorkina/Documents/backup/scripts/MoE/sentence/moe_predictions_test_sentence.csv\")\n"
   ],
   "id": "65572a02ba9fd69e",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:20:59.634039Z",
     "start_time": "2025-07-22T21:20:59.616534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run this df preparation of you want to get year prediction aggregated by text; run the next cell to get per-batch dataset\n",
    "\n",
    "agg_df = df.groupby(\"row_idx_df\").agg({\n",
    "    \"loss\": [\"mean\", \"std\", \"count\"],\n",
    "    \"perplexity\": [\"mean\", \"std\"],\n",
    "    \"weight_0\": \"mean\",\n",
    "    \"weight_1\": \"mean\",\n",
    "    \"weight_2\": \"mean\",\n",
    "    \"actual_year\": \"first\"\n",
    "})\n",
    "\n",
    "# Flatten column names\n",
    "agg_df.columns = ['loss_mean', 'loss_std', 'batch_count', \"perplexity_mean\", \"perplexity_std\", 'weight_0', 'weight_1', 'weight_2', 'actual_year']\n",
    "\n",
    "agg_df = agg_df.reset_index()\n",
    "\n",
    "# Calculate the sum of weights for each row\n",
    "weight_sum = agg_df[['weight_0', 'weight_1', 'weight_2']].sum(axis=1)\n",
    "\n",
    "# Normalize each weight column\n",
    "agg_df['weight_0'] = agg_df['weight_0'] / weight_sum\n",
    "agg_df['weight_1'] = agg_df['weight_1'] / weight_sum\n",
    "agg_df['weight_2'] = agg_df['weight_2'] / weight_sum\n",
    "\n",
    "\n",
    "# Bin actual years into their respective expert periods\n",
    "def assign_period(year):\n",
    "    if 1710 <= year < 1780:\n",
    "        return \"1710–1780\"\n",
    "    elif 1780 <= year < 1850:\n",
    "        return \"1780–1850\"\n",
    "    elif 1850 <= year <= 1920:\n",
    "        return \"1850–1920\"\n",
    "    else:\n",
    "        return \"Out of range\"\n",
    "\n",
    "agg_df[\"actual_period\"] = agg_df[\"actual_year\"].apply(assign_period)\n",
    "\n",
    "weight_cols = [\"weight_0\", \"weight_1\", \"weight_2\"]\n",
    "agg_df[\"dominant_expert\"] = agg_df[weight_cols].idxmax(axis=1)\n",
    "\n",
    "expert_period_map = {\n",
    "    \"weight_0\": \"1710–1780\",\n",
    "    \"weight_1\": \"1780–1850\",\n",
    "    \"weight_2\": \"1850–1920\"\n",
    "}\n",
    "agg_df[\"predicted_period\"] = agg_df[\"dominant_expert\"].map(expert_period_map)\n"
   ],
   "id": "2aba515c79509424",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:21:05.918864Z",
     "start_time": "2025-07-22T21:21:05.911868Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run this cell if you want to generate per-batch level dataset\n",
    "all_df = df.copy()\n",
    "\n",
    "\n",
    "# Bin actual years into their respective expert periods\n",
    "def assign_period(year):\n",
    "    if 1710 <= year < 1780:\n",
    "        return \"1710–1780\"\n",
    "    elif 1780 <= year < 1850:\n",
    "        return \"1780–1850\"\n",
    "    elif 1850 <= year <= 1920:\n",
    "        return \"1850–1920\"\n",
    "    else:\n",
    "        return \"Out of range\"\n",
    "\n",
    "all_df[\"actual_period\"] = all_df[\"actual_year\"].apply(assign_period)\n",
    "\n",
    "weight_cols = [\"weight_0\", \"weight_1\", \"weight_2\"]\n",
    "all_df[\"dominant_expert\"] = all_df[weight_cols].idxmax(axis=1)\n",
    "\n",
    "expert_period_map = {\n",
    "    \"weight_0\": \"1710–1780\",\n",
    "    \"weight_1\": \"1780–1850\",\n",
    "    \"weight_2\": \"1850–1920\"\n",
    "}\n",
    "all_df[\"predicted_period\"] = all_df[\"dominant_expert\"].map(expert_period_map)\n"
   ],
   "id": "d7488bd60ca1ca0b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "ccb12e92-3294-4128-8a14-8d1b60d95b2e",
   "metadata": {},
   "source": "### Year Prediction (final function)"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:21:08.060397Z",
     "start_time": "2025-07-22T21:21:08.053543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "index_to_year = {\n",
    "    0: \"[1710-1780]\",\n",
    "    1: \"[1780-1850]\",\n",
    "    2: \"[1850-1920]\"\n",
    "}\n",
    "\n",
    "def predict_year_and_calculate_error(df):\n",
    "    \"\"\"\n",
    "    Predicts the year for each row in the DataFrame based on a given confidence threshold.\n",
    "    Also calculates the absolute error and appends the predictions to the DataFrame.\n",
    "    \"\"\"\n",
    "    predicted_years = []\n",
    "    abs_errors = []\n",
    "    cases = []\n",
    "\n",
    "    # Process each row in the DataFrame\n",
    "    for _, row in df.iterrows():\n",
    "        probs = [row[\"weight_0\"], row[\"weight_1\"], row[\"weight_2\"]]\n",
    "        actual_year = row[\"actual_year\"]\n",
    "\n",
    "        top2 = sorted(enumerate(probs), key=lambda x: x[1], reverse=True)[:2]\n",
    "        idx_a, w_a = top2[0]\n",
    "        idx_b, w_b = top2[1]\n",
    "\n",
    "        range_a = index_to_year[idx_a]\n",
    "        range_b = index_to_year[idx_b]\n",
    "\n",
    "        l_a, r_a = map(int, range_a.strip(\"[]\").split(\"-\"))\n",
    "        l_b, r_b = map(int, range_b.strip(\"[]\").split(\"-\"))\n",
    "\n",
    "        adjacent = r_a == l_b or r_b == l_a\n",
    "\n",
    "        if adjacent:\n",
    "            case = \"A\"\n",
    "            w_s = w_b + w_a\n",
    "            if l_a < l_b:\n",
    "                pred_year = r_a + 70 * (w_b - w_a) / w_s\n",
    "            else:\n",
    "                pred_year = r_b + 70 * (w_a - w_b) / w_s\n",
    "        else:\n",
    "            case = \"B\"\n",
    "            w_s = probs[2] + probs[0]\n",
    "            pred_year = 1815 + 105 * (probs[2] - probs[0]) / w_s\n",
    "\n",
    "\n",
    "        pred_year = round(pred_year)\n",
    "        abs_error = abs(pred_year - int(actual_year))\n",
    "\n",
    "        predicted_years.append(pred_year)\n",
    "        abs_errors.append(abs_error)\n",
    "        cases.append(case)\n",
    "\n",
    "    # Append new columns to the DataFrame\n",
    "    df[\"predicted_year\"] = predicted_years\n",
    "    df[\"absolute_error\"] = abs_errors\n",
    "    df[\"case\"] = cases\n",
    "\n",
    "    return df"
   ],
   "id": "cbe5c19b-77cf-417e-a301-df9b69584dba",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-22T21:21:11.725347Z",
     "start_time": "2025-07-22T21:21:11.666143Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Run the year prediction\n",
    "year_prediction_batches = predict_year_and_calculate_error(all_df)\n",
    "year_prediction_texts = predict_year_and_calculate_error(agg_df)"
   ],
   "id": "b4082fb7965678c3",
   "outputs": [],
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
